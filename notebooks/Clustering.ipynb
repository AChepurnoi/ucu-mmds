{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import col, lower, regexp_replace, split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_path = \"../csv_data/top-10-sample-output.csv\"\n",
    "df_path = \"../csv_data/sample-output.csv\"\n",
    "df = spark.read.csv(df_path, inferSchema=True, header=True, multiLine=True, escape='\"')\n",
    "pdf = pd.read_csv(df_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns: ['_c0', 'comment', 'contributor', 'format', 'id', 'ip', 'model', 'ns', 'parentid', 'restrictions', 'revision', 'sha1', 'text', 'timestamp', 'title', 'username']\n",
      "Unique values for..\n",
      "\t format : ['text/x-wiki']\n",
      "\t model : ['wikitext']\n",
      "\t ns : [  0   4 100  12]\n",
      "\t contributor : ['  ' ' ']\n",
      "\t revision : ['         ' '          ' '        ']\n",
      "\t restrictions : [nan 'move=:edit=' 'move=sysop' 'edit=autoconfirmed:move=autoconfirmed'\n",
      " 'sysop' 'edit=sysop:move=sysop']\n",
      "Useful columns: ['sha1', 'timestamp', 'title', 'text']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Filtering columns\n",
    "    Useful: sha1 (as identifier),  timestamp, title, text\n",
    "    Questionable: user, comment, ip, id (there are different articles with the same id), parentid, restrictions\n",
    "    Not useful (no unique info): model, format, ns, contributor, revision, restrictions\n",
    "\"\"\" \n",
    "\n",
    "print(\"All columns:\", df.columns)\n",
    "print(\"Unique values for..\")\n",
    "for column in [\"format\", \"model\", \"ns\", \"contributor\", \"revision\", \"restrictions\"]:\n",
    "    print(\"\\t\", column, \":\", pdf[column].unique())\n",
    "    \n",
    "useful_columns = [\"sha1\", \"timestamp\", \"title\", \"text\"]\n",
    "print(\"Useful columns:\", useful_columns)\n",
    "\n",
    "clean_df = df[useful_columns]\n",
    "clean_pdf = pdf[useful_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+--------------------+\n",
      "|                sha1|          timestamp|               title|                text|\n",
      "+--------------------+-------------------+--------------------+--------------------+\n",
      "|42l0cvblwtb4nnupx...|2018-08-14 09:47:24| AccessibleComputing|#REDIRECT [[Compu...|\n",
      "|2d0jpq2oi6jjc6hbb...|2019-06-16 03:28:20|           Anarchism|{{redirect2|Anarc...|\n",
      "|iv7s0lr40b17x33tf...|2017-06-05 07:18:18|  AfghanistanHistory|#REDIRECT [[Histo...|\n",
      "|39r4w8qg62iexlysk...|2017-06-05 07:18:23|AfghanistanGeography|#REDIRECT [[Geogr...|\n",
      "|fncm9bh9l25bmvyzq...|2017-06-05 07:19:42|   AfghanistanPeople|#REDIRECT [[Demog...|\n",
      "|q8gdi8070w6yitd4h...|2017-06-05 07:19:45|AfghanistanCommun...|#REDIRECT [[Commu...|\n",
      "|miah0hk4ws6ctake8...|2017-06-05 00:42:11|AfghanistanTransp...|#REDIRECT [[Trans...|\n",
      "|j013t2shx5j3p2gq4...|2017-06-05 00:43:11| AfghanistanMilitary|#REDIRECT [[Afgha...|\n",
      "|80xx3tzgvcdioufir...|2017-06-05 00:43:14|AfghanistanTransn...|#REDIRECT [[Forei...|\n",
      "|f0x0fdqkexsha1xdm...|2017-06-05 07:19:50| AssistiveTechnology|#REDIRECT [[Assis...|\n",
      "+--------------------+-------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----------------------------------------------------------------------------------------------+\n",
      "|text                                                                                          |\n",
      "+----------------------------------------------------------------------------------------------+\n",
      "|#REDIRECT [[Computer accessibility]]\n",
      "\n",
      "{{R from move}}\n",
      "{{R from CamelCase}}\n",
      "{{R unprintworthy}}|\n",
      "+----------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df.show(10)\n",
    "clean_df[[\"text\"]].show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sha1: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "Size of the DataFrame: 19821 records\n"
     ]
    }
   ],
   "source": [
    "clean_df.printSchema()\n",
    "print(\"Size of the DataFrame: {} records\".format(clean_df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### below is WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                            |\n",
      "+------------------------------------------------------------------------------------------------+\n",
      "|[#REDIRECT [[Computer accessibility]]\n",
      "\n",
      "{{R from move}}\n",
      "{{R from CamelCase}}\n",
      "{{R unprintworthy}}]|\n",
      "+------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_text(c):\n",
    "#     c = lower(c)\n",
    "#     c = regexp_replace(c, \"[^a-zA-Z0-9\\\\s]\", \"\")\n",
    "#     c = split(c, \"\\\\n+\")\n",
    "    c = split(c, \"==[a-zA-Z0-9.,!?\\\\s]==\")\n",
    "    return c\n",
    "\n",
    "clean_df.select(clean_text(col(\"text\")).alias(\"text\")).show(1, truncate=False)\n",
    "# \n",
    "# clean_df.printSchema()\n",
    "# clean_df.select(\"text\").map()#clean_text).show(10)\n",
    "# clean_df.withColumn(\"test\", clean_df.text[0]).select(\"test\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comment', 'contributor', 'format', 'id', 'ip', 'model', 'ns', 'parentid', 'restrictions', 'revision', 'sha1', 'text', 'timestamp', 'title', 'username']\n",
      "\n",
      "\n",
      "ARTICLE 1 | Anarchism\n",
      "> Text:\n",
      " {{redirect2|Anarchist|Anarchists|other uses|Anarchists (disambiguation)}}\n",
      "{{pp-move-indef}}{{short description|Political philosophy that advocates self-governed societies}}\n",
      "{{use dmy dates|date=July 2018}}\n",
      "{{use British English|date=January 2014}}\n",
      "{{anarchism sidebar}}\n",
      "\n",
      "\n",
      "ARTICLE 2 | AfghanistanHistory\n",
      "> Text:\n",
      " #REDIRECT [[History of Afghanistan]]\n",
      "\n",
      "{{Redirect category shell|1=\n",
      "{{R from CamelCase}}\n",
      "}}\n",
      "\n",
      "\n",
      "ARTICLE 3 | AfghanistanGeography\n",
      "> Text:\n",
      " #REDIRECT [[Geography of Afghanistan]]\n",
      "\n",
      "{{Redirect category shell|1=\n",
      "{{R from CamelCase}}\n",
      "}}\n",
      "\n",
      "\n",
      "ARTICLE 4 | AfghanistanPeople\n",
      "> Text:\n",
      " #REDIRECT [[Demographics of Afghanistan]]\n",
      "\n",
      "{{Redirect category shell|1=\n",
      "{{R from CamelCase}}\n",
      "}}\n"
     ]
    }
   ],
   "source": [
    "def get_features_from_text(text):\n",
    "    textFile = spark.read.text(text)\n",
    "#     features = pd.Series()\n",
    "#     features[\"redirect\"] = text[:9] == \"#REDIRECT\"\n",
    "#     return features\n",
    "    return textFile\n",
    "\n",
    "print(list(pdf.columns))\n",
    "\n",
    "\n",
    "# for row in df.iterrows():\n",
    "for i in range(1,5):\n",
    "    row = pdf.loc[i]\n",
    "    print(\"\\n\\nARTICLE\", i, \"|\", row[\"title\"])\n",
    "#     print(\"> Comment:\", row[\"comment\"])\n",
    "#     print(\"> User:\", row[\"username\"])\n",
    "#     print(row[\"ns\"])\n",
    "    print(\"> Text:\\n\", \"\\n\".join(row[\"text\"].split('\\n')[:5]))\n",
    "#     print(\"> Features:\\n\", get_features_from_text(row[\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.clustering import BisectingKMeans\n",
    "\n",
    "# # Loads data.\n",
    "# dataset = spark.read.format(\"libsvm\").load(\"sample_kmeans_data.txt\")\n",
    "\n",
    "# # Trains a bisecting k-means model.\n",
    "# bkm = BisectingKMeans().setK(2).setSeed(1)\n",
    "# model = bkm.fit(dataset)\n",
    "\n",
    "# # Evaluate clustering.\n",
    "# cost = model.computeCost(dataset)\n",
    "# print(\"Within Set Sum of Squared Errors = \" + str(cost))\n",
    "\n",
    "# # Shows the result.\n",
    "# print(\"Cluster Centers: \")\n",
    "# centers = model.clusterCenters()\n",
    "# for center in centers:\n",
    "#     print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
