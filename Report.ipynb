{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversity of Wikipedia article references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining massive databases course final project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem motivation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diversity of resources and content matters. When people are obtaining new knowledge, they don't want to be fooled with fake news or believe in information without proof from other authorized source. A lot of Wikipedia articles have a problem with poor filled or unreferenced sources of information, so, in the era of post-truth, there is a huge need for automatic detection of articles with poor sources distribution (or without sources as well). <br> <br>\n",
    "    Our solution can help editors as well, because they will have possibility to concentrate on the truly non-filled arctiles. Also, the main improvement for editors and readers that the differences in the same article across languages can be detected and fixed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the quality of the article, based on the references, in an unsupervised way. Unite and check the results of our modeling with results from ORES model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work pipeline: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download wikipedia XML dumps: <br> <br>\n",
    " * We are using page article multistream dumps. To get faster development loops so far we worked with a single dump, next we will run the full pipeline on the whole wikipedia data. <br> <br>\n",
    "* Parse XML to CSV using streaming XML parser: <br> <br>\n",
    " * We are using lxml and handwritten parser that goes through the file tag by tag and parses articles and meta information and article and last revision. The data we are fetching includes article text, title, revision author, revision comment and timestamp. <br> <br>\n",
    "* Fetch ORES assessments: <br> <br>\n",
    " * Here we use mwapi and ORES web service to get article scores <br> <br>\n",
    "* Inspect internal structure of text: <br> <br>\n",
    " * Wikipedia articles have its own syntax for declaring blocks inside\n",
    "   article: source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add smth else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Were built features that reflect diversity of text, sources and links: <br> <br>\n",
    "* Internal, external references count <br> <br>\n",
    "* Average number of references per block of text (Number of references / Number of paragraphs) <br> <br>\n",
    "* Citations count (Journals, Books, Web, News) <br> <br>\n",
    "* Number of images, files, etc in the articles <br> <br>\n",
    "* Number of non-approved references (“citation needed”) <br> <br>\n",
    "* Headings count (different levels) <br> <br>\n",
    "* ORES features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download here the features dataframe and demonstrate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette coefficient theory (more detailed, mb outputs from plots post also here) + clusteing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call there python ./test.py -t \"Principal component analysis\"\n",
    "# and test smth else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future work: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> \n",
    "* Create supervised machine learning model with ORES as labels and our features as inputs. The resulted model should be transferred to the other languages that didn’t support by ORES (like Ukrainian) <br> <br> \n",
    "* Test the PySpark MLP / Random Forest / Gradient boosting and get the features importance (visualize the pluses and minuses of the articles references) <br> <br>\n",
    "* Fix clustering with ORES features <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
